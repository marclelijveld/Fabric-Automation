{"cells":[{"cell_type":"markdown","source":["# Save Admin Monitoring data to Lakehouse\n","This notebook is intended to collect data from the Admin Monitoring workspace and save to a Fabric Lakehouse.\n","\n","#### Conceptual overview of the solution\n","As the semantic models in the admin monitoring workspace are in a protected state, you cannot directly connect to the semantic model to collect data. Therefore, an intermediate [composite model](https://learn.microsoft.com/en-us/power-bi/transform-model/desktop-composite-models?WT.mc_id=DP-MVP-5003435) is required. This composite model can be used to directly enrich the data but will not extend the retention. To extract the data and save it to your own lakehouse, you have to run this notebook on top of the composite model. \n","\n","In below image you will see an conceptual overview. This notebook is the highlighted notebook. \n","<img src=\"https://dataandai.wordpress.com/wp-content/uploads/2025/04/adminmonitoringworkspacedatacollection-conceptualoverview.png" width=\"1000px\">\n","\n","#### <mark>**Risks and caveats:**</mark>\n","\n","**Solution impact**\n","- Need to deduplicate dimensional data - as metadata may change over time (or consider slowly changing dimensions instead). This notebook does not deduplicate the data in the destination lakehouse. \n","- Semantic model definition of the Admin Monitoring Semantic Model may change through updates, which may break this data extraction notebook.\n","- Impact on capacity through direct query on Admin & Monitoring artifacts. \n","\n","**Permissions & security risks**\n","- Admin & monitoring artifacts are available to a limited group - for a reason.\n","- Having the data in a lakehouse, makes you responsible to manage retention and security!\n"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"c8b09e50-9b0b-43e9-9016-a980eb69ef25"},{"cell_type":"markdown","source":["## Generic code"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"684c63bc-cba6-47b0-b84f-e49e8b3de655"},{"cell_type":"code","source":["# Set some variables\n","dataset_name = \"SM_MONIT_CompositeModel\" # Enter the name of the composite model here\n","lakehouse_name = \"LH_STORE_AdminMonitoring\" # Enter the name of the destination lakehouse here. Make sure the lakehouse is also connected as default lakehouse to this notebook. "],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":3,"statement_ids":[3],"state":"finished","livy_statement_state":"available","session_id":"bbbe73aa-6692-4706-b39a-a54581506b34","normalized_state":"finished","queued_time":"2025-03-19T20:33:50.3807965Z","session_start_time":"2025-03-19T20:33:50.3821931Z","execution_start_time":"2025-03-19T20:37:44.8048684Z","execution_finish_time":"2025-03-19T20:37:45.2889489Z","parent_msg_id":"2e5b63cc-f461-44fd-b7da-a546ed2bb2d4"},"text/plain":"StatementMeta(, bbbe73aa-6692-4706-b39a-a54581506b34, 3, Finished, Available, Finished)"},"metadata":{}}],"execution_count":1,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"d2f3262b-e350-4e3c-886a-95337e970bc9"},{"cell_type":"markdown","source":["## Import libraries"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"974b7669-1daf-4e96-a4a6-a8bc37f38ea9"},{"cell_type":"code","source":["# Define functions\n","import pyspark.sql.functions as F\n","import sempy.fabric as fabric\n","import pandas as pd\n","from pyspark.sql import SparkSession\n","import re"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":49,"statement_ids":[49],"state":"finished","livy_statement_state":"available","session_id":"bbbe73aa-6692-4706-b39a-a54581506b34","normalized_state":"finished","queued_time":"2025-03-19T20:56:56.3002053Z","session_start_time":null,"execution_start_time":"2025-03-19T20:56:56.3018478Z","execution_finish_time":"2025-03-19T20:56:56.7153348Z","parent_msg_id":"49e58659-56b3-4aeb-b872-1edcdfcda978"},"text/plain":"StatementMeta(, bbbe73aa-6692-4706-b39a-a54581506b34, 49, Finished, Available, Finished)"},"metadata":{}}],"execution_count":47,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"11cb205e-81fc-4909-80e9-91369b5f8c12"},{"cell_type":"markdown","source":["### Describing need for functions\n","A Fabric lakehouse cannot handle special characters or spaces. \n","As Power BI Semantic models likely have spaces and special characters, these functions will remove any from both table names and columns names. \n","This to avoid any conflicts in saving them to the destination lakehouse. "],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"a3c2328a-0352-4137-abb3-61e5db3782fd"},{"cell_type":"code","source":["# Function to escape table names with spaces or special characters\n","def escape_table_name(table_name):\n","    return f\"`{table_name}`\" if ' ' in table_name or not table_name.isidentifier() else table_name"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":56,"statement_ids":[56],"state":"finished","livy_statement_state":"available","session_id":"bbbe73aa-6692-4706-b39a-a54581506b34","normalized_state":"finished","queued_time":"2025-03-19T20:59:15.4306649Z","session_start_time":null,"execution_start_time":"2025-03-19T20:59:15.4322584Z","execution_finish_time":"2025-03-19T20:59:15.7736938Z","parent_msg_id":"4aaef073-721e-46e0-86f3-6c0981c91d2f"},"text/plain":"StatementMeta(, bbbe73aa-6692-4706-b39a-a54581506b34, 56, Finished, Available, Finished)"},"metadata":{}}],"execution_count":54,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"51c36e7f-7657-4e48-8fc4-03e60086634a"},{"cell_type":"code","source":["# Function to sanitize column names (removes spaces and special characters)\n","def sanitize_column_names(columns):\n","    return [re.sub(r'[^A-Za-z0-9_]', '_', col) for col in columns]"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":55,"statement_ids":[55],"state":"finished","livy_statement_state":"available","session_id":"bbbe73aa-6692-4706-b39a-a54581506b34","normalized_state":"finished","queued_time":"2025-03-19T20:59:14.2963853Z","session_start_time":null,"execution_start_time":"2025-03-19T20:59:14.2980573Z","execution_finish_time":"2025-03-19T20:59:14.6733377Z","parent_msg_id":"6ce59046-6be6-400b-a796-bfce8fe5f036"},"text/plain":"StatementMeta(, bbbe73aa-6692-4706-b39a-a54581506b34, 55, Finished, Available, Finished)"},"metadata":{}}],"execution_count":53,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"8ad78b2b-255a-4867-9cf6-b995c1bdab89"},{"cell_type":"markdown","source":["## Use sempy to collect information about the semantic model\n","This section first collects a list of all tables in the semantic model combined with some meta information like the state of the table (such as hidden state)"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"30550584-ae8e-4aad-ba92-a6492d368e82"},{"cell_type":"code","source":["# Get the list of tables from the Semantic Model\n","tables = fabric.list_tables(dataset_name)\n","tables"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":50,"statement_ids":[50],"state":"finished","livy_statement_state":"available","session_id":"bbbe73aa-6692-4706-b39a-a54581506b34","normalized_state":"finished","queued_time":"2025-03-19T20:56:58.2436695Z","session_start_time":null,"execution_start_time":"2025-03-19T20:56:58.2452133Z","execution_finish_time":"2025-03-19T20:56:58.6238936Z","parent_msg_id":"a042d94b-127d-4826-aab2-8366e77a4cc4"},"text/plain":"StatementMeta(, bbbe73aa-6692-4706-b39a-a54581506b34, 50, Finished, Available, Finished)"},"metadata":{}},{"output_type":"execute_result","execution_count":149,"data":{"text/plain":"             Name Description  Hidden Data Category   Type\n0            Date               False                Table\n1       _Measures               False                Table\n2       Workspace               False                Table\n3           Audit               False                Table\n4        Capacity               False                Table\n5            User               False                Table\n6       Changelog                True                Table\n7    Fabric Items               False                Table\n8   Refresh Stats                True                Table\n9  Orch Structure               False                Table","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Name</th>\n      <th>Description</th>\n      <th>Hidden</th>\n      <th>Data Category</th>\n      <th>Type</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Date</td>\n      <td></td>\n      <td>False</td>\n      <td></td>\n      <td>Table</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>_Measures</td>\n      <td></td>\n      <td>False</td>\n      <td></td>\n      <td>Table</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Workspace</td>\n      <td></td>\n      <td>False</td>\n      <td></td>\n      <td>Table</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Audit</td>\n      <td></td>\n      <td>False</td>\n      <td></td>\n      <td>Table</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Capacity</td>\n      <td></td>\n      <td>False</td>\n      <td></td>\n      <td>Table</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>User</td>\n      <td></td>\n      <td>False</td>\n      <td></td>\n      <td>Table</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Changelog</td>\n      <td></td>\n      <td>True</td>\n      <td></td>\n      <td>Table</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Fabric Items</td>\n      <td></td>\n      <td>False</td>\n      <td></td>\n      <td>Table</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Refresh Stats</td>\n      <td></td>\n      <td>True</td>\n      <td></td>\n      <td>Table</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Orch Structure</td>\n      <td></td>\n      <td>False</td>\n      <td></td>\n      <td>Table</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":48,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"598ea7ec-1c41-4de1-8fa2-741b0e2d6f30"},{"cell_type":"markdown","source":["#### Explain filter conditions\n","Hidden tables are likely hidden for a reason. Therefore they are excluded from extraction in this step. Also, the table named \"_Measures\" is excluded from the list, as only tables which include columns can be extracted from the semantic model. Given the \"_Measures\" table does not contain any columns and is just a placeholder for all measures stored in the semantic model, we exclude this from the extraction list as well. "],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"5149616a-5e53-4551-98e1-71dcd2b4df11"},{"cell_type":"code","source":["# Filter out hidden tables and exclude '_Measures'\n","visible_tables = tables[(tables[\"Hidden\"] == False) & (tables[\"Name\"] != \"_Measures\")]\n","\n","# Print the filtered list\n","print(\"Visible tables in dataset:\", visible_tables)"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":51,"statement_ids":[51],"state":"finished","livy_statement_state":"available","session_id":"bbbe73aa-6692-4706-b39a-a54581506b34","normalized_state":"finished","queued_time":"2025-03-19T20:57:00.2193187Z","session_start_time":null,"execution_start_time":"2025-03-19T20:57:00.2209133Z","execution_finish_time":"2025-03-19T20:57:00.6420908Z","parent_msg_id":"7d5d40c6-7441-4bce-b6e2-8a42b2b3ac4f"},"text/plain":"StatementMeta(, bbbe73aa-6692-4706-b39a-a54581506b34, 51, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Visible tables in dataset:              Name Description  Hidden Data Category   Type\n0            Date               False                Table\n2       Workspace               False                Table\n3           Audit               False                Table\n4        Capacity               False                Table\n5            User               False                Table\n7    Fabric Items               False                Table\n9  Orch Structure               False                Table\n"]}],"execution_count":49,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"f09495be-f9bd-496a-9108-f0b95e9cb4eb"},{"cell_type":"markdown","source":["# Extract each table and save to lakehouse\n","This section extracts all data from the filtered list of semantic model tables. All this data will be saved to the attached lakehouse, in which the earlier declared functions are used to remove any special characters and spaces from the table and column names. \n","\n","**Note: This example script overwrites the destination tables at each run, to build up history, the write mode should be set to <mark>\"append\"</mark>.**"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"f21bdbe9-d174-492b-8bf1-8b74ae7c6255"},{"cell_type":"code","source":["# Loop through each visible table\n","for table in visible_tables[\"Name\"]:\n","    print(f\"Processing table: {table}\")\n","\n","    try:\n","        # Read the table from Semantic Link\n","        df_fabric = fabric.read_table(dataset_name, table)\n","\n","        # Convert FabricDataFrame to Pandas DataFrame using `to_dict()`\n","        df_pandas = pd.DataFrame(df_fabric.to_dict())\n","\n","        # Sanitize column names\n","        df_pandas.columns = sanitize_column_names(df_pandas.columns)\n","\n","        # Convert Pandas DataFrame to PySpark DataFrame\n","        df_spark = spark.createDataFrame(df_pandas)\n","\n","        # Escape table name if necessary\n","        table_name_escaped = escape_table_name(table)\n","\n","        # Save to Lakehouse (overwrite mode) with escaped table name\n","        df_spark.write.mode(\"overwrite\").saveAsTable(table_name_escaped)\n","\n","        print(f\"Table {table} saved successfully.\")\n","    except Exception as e:\n","        print(f\"Error processing table {table}: {e}\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":57,"statement_ids":[57],"state":"finished","livy_statement_state":"available","session_id":"bbbe73aa-6692-4706-b39a-a54581506b34","normalized_state":"finished","queued_time":"2025-03-19T20:59:25.8679166Z","session_start_time":null,"execution_start_time":"2025-03-19T20:59:25.8695219Z","execution_finish_time":"2025-03-19T20:59:58.0266503Z","parent_msg_id":"420d5093-8dfa-4b89-920a-3133fd42eb0f"},"text/plain":"StatementMeta(, bbbe73aa-6692-4706-b39a-a54581506b34, 57, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Processing table: Date\nTable Date saved successfully.\nProcessing table: Workspace\nTable Workspace saved successfully.\nProcessing table: Audit\nTable Audit saved successfully.\nProcessing table: Capacity\nTable Capacity saved successfully.\nProcessing table: User\nTable User saved successfully.\nProcessing table: Fabric Items\nTable Fabric Items saved successfully.\nProcessing table: Orch Structure\nTable Orch Structure saved successfully.\n"]}],"execution_count":55,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"f48a5bb2-88a3-419c-8319-09dec145e5db"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","language":"Python","display_name":"Synapse PySpark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{"lakehouse":{"default_lakehouse":"05cd79a2-f1dd-44f7-9f44-345412a903a2","default_lakehouse_name":"LH_STORE_AdminMonitoring","default_lakehouse_workspace_id":"635ea462-7ec7-4afc-bb51-00b0218c3178"}}},"nbformat":4,"nbformat_minor":5}
